{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 35、使用AdaBoost对房价进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost不仅可以用于分类问题，还可以用于回归分析。\n",
    "\n",
    "那么回忆一下，什么是分类，什么是回归？实际上分类和回归的本质是一样的，都是对未知事物做预测。不同之处在于输出结果的类型，分类输出的是一个离散值，因为物体的分类数有限的，而回归输出的是连续值，也就是在一个区间分为之内任何取值都有可能。\n",
    "\n",
    "这次的主要目标是使用AdaBoost预测房价，这是一个回归问题。除了对项目进行编码实战外，还要掌握：\n",
    "- 1、AdaBoost工具的使用，包括使用AdaBoost进行分类，以及回归分析。\n",
    "- 2、使用其他的回归工具，比如决策树的回归，对AdaBoost回归和决策树回归的结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何使用AdaBoost工具"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以直接在sklearn中使用AdaBoost。如果我们要用AdaBoost进行分类，需要在使用前引用代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道，如果看到了Classifier这个类，一般都会对应着Regressor类。AdaBoost也不例外，回归工具包的应用代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先看下如何在sklearn中创建AdaBoost分类器。\n",
    "\n",
    "我们需要使用AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)这个函数，其中有几个比较主要的参数，解析如下：\n",
    "\n",
    "- 1、**base_estimator** :代表的是弱分类器。在AdaBoost的分类器和回归器中都有这个参数，在AdaBoost中默认使用的是决策树，一般我们不需要修改这个参数，当然也可以指定具体的分类器。\n",
    "- 2、**n_estimators** ：算法的最大迭代次数，也是分类器的个数，每一次迭代都会引入一个新的弱分类器来增加原有的分类器的组合能力。默认是50.\n",
    "- 3、**Learning_rate** :代表学习率，取值在0-1之间，默认是1.0。如果学习率较小，就需要比较多的迭代次数才能收敛，也就是说学习率和迭代次数是有相关性的。当你调整Learning_rate的时候，往往也需要调整n_estimators这个参数。\n",
    "- 4、**algorithm**：代表的是我们要采用哪一种Boosting算法，一共有两种选择：SAMME和SAMME.R。默认是SAMME.R。这两者之间的区别在于对弱分类权重的计算方式不同。\n",
    "- 5、**random_rate** :代表的是随机数种子的设置，默认是None。随机种子是用来控制随机模式的，当随机种子取了一个值，也就是确定了一种随机规则，其他人取这个值可以得到同样的效果。如果不设置随机种子，每次得到的随机数也就不同。\n",
    "\n",
    "那么如何创建AdaBoost回归呢？\n",
    "\n",
    "我们可以使用AdaBoostRegressor(base_estimator=None, n_estimator=50, learning_rate=1.0, loss='linear',random_state=None)这个函数。\n",
    "\n",
    "我们能够看出回归和分类的参数基本上是一致的，不同点在于回归算法里面没有algorithm这个参数，但是多出了一个loss参数。\n",
    "\n",
    "loss代表的是损失函数的设置，一共有3种选择器，分别为linear、square和exponential，它们的含义分别为线性、平凡和指数。默认是线性。一般采用线性就可以得到不错的效果。\n",
    "\n",
    "创建好AdaBoost分类器或者回归器之后，我们就可以输入训练集对它进行训练。使用的是fit函数，传入的训练集中的样本特征值train_X和结果train_y,模型会自动拟合。使用predict函数进行预测，传入的测试集中的样本特征值test_X,然后就可以得到预测的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何使用AdaBoost对房价进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "了解了AdaBoost工具之后，我们可以看一下sklearn中自带的波士顿房价数据集。\n",
    "\n",
    "这个数据集中一共包含506条房屋信息，每一条信息中都包含了13个指标，以及一个房屋价位。\n",
    "\n",
    "13个指标的涵义可以参考下面的表格：\n",
    "\n",
    "|指标|含义|\n",
    "|--|--|\n",
    "|CRIM|城镇人均犯罪率|\n",
    "|ZN|住宅用地比例|\n",
    "|INDUS|非零售商业用地比例|\n",
    "|CHAS|CHAS变量，0或者1|\n",
    "|NOX|一氧化氮浓度|\n",
    "|RM|每个住宅的平均房间数|\n",
    "|AGE|1940年以前自用房屋的比例|\n",
    "|DIS|距离五个波士顿就业中心的加权距离|\n",
    "|RAD|距离高速公路的便捷指数|\n",
    "|TAX|该地区每一万美元的不动产税率|\n",
    "|PRTATIO|该地区教师学生比例|\n",
    "|B|该地区黑人比例|\n",
    "|LSTAT|该地区中低收入阶层比例|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些指标分得还是很细的，但是实际上，我们不用关心具体的含义，要做的就是如何通过这13个指标推出最终的房价结果。\n",
    "\n",
    "有了之前的基础，这个数据集的预测并不复杂。\n",
    "\n",
    "首先加载数据，将数据分割成训练集和测试集，然后创建AdaBoost回归模型，传入的训练数据进行拟合，再传入测试集数据进行预测，就可以得到预测的结果。最后将预测的结果与实际结果进行对比，得到两者之间的误差。具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "房价预测结果 [19.12346939 10.91219512 13.79491525 17.31782178 23.05502392 20.93571429\n",
      " 26.01470588 18.15753425 32.50333333 18.37361111 26.84753086 33.85964912\n",
      " 12.16842105 25.31894737 12.07384615 25.24438776 16.98181818 15.255\n",
      " 27.64532374 26.01470588 17.58333333 17.31782178 16.86521739 18.77530864\n",
      " 31.99245283 17.31782178 21.20412371 25.24438776 12.16842105 29.05952381\n",
      " 16.02179487 26.84753086 10.91219512 21.20412371 26.01470588 31.99245283\n",
      " 25.24438776 12.16842105 13.79491525 25.31894737 15.16521739 13.12857143\n",
      " 31.99245283 16.02179487 25.61597633 19.12346939 16.92280702 19.4218543\n",
      " 25.61597633 19.12346939 16.6509434  32.50333333 15.16521739 16.02179487\n",
      " 25.24438776 20.56315789 25.24438776 16.02179487 26.01470588 22.48522727\n",
      " 18.77530864 16.02179487 43.86666667 20.58       16.02179487 25.24438776\n",
      " 25.61597633 12.16842105 18.37       26.01470588 22.57905759 18.37\n",
      " 17.58333333 28.27443609 19.4218543  43.54705882 15.24375    12.07384615\n",
      " 16.92280702 25.24438776 19.93194444 16.02179487 13.12857143 25.61597633\n",
      " 20.56315789 21.192      47.12       16.02179487 44.54761905 32.45581395\n",
      " 31.99245283 18.77530864 19.4218543  16.61666667 15.24375    32.50333333\n",
      " 25.24438776 23.0734375  18.37       18.15753425 16.02179487 19.59894737\n",
      " 26.01470588 25.61597633 12.16842105 15.16521739 11.14827586 25.61597633\n",
      " 12.16842105 25.61597633 45.25681818 13.12857143 17.31782178 25.24438776\n",
      " 31.99245283 25.24438776 22.57905759 21.20412371 28.27443609 20.56315789\n",
      " 18.77530864 18.15753425 12.16842105 20.56315789 20.90517241 16.92280702\n",
      " 43.86666667]\n",
      "均方误差 =  18.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# 加载数据\n",
    "data = load_boston()\n",
    "# 分割数据\n",
    "train_x, test_x, train_y, test_y = train_test_split(data.data, data.target, test_size=0.25, random_state=33)\n",
    "# 使用AdaBoost回归模型\n",
    "regressor = AdaBoostRegressor()\n",
    "regressor.fit(train_x, train_y)\n",
    "# 回归测试集预测\n",
    "pred_y = regressor.predict(test_x) \n",
    "# 计算均方误差\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"房价预测结果\", pred_y)\n",
    "print(\"均方误差 = \",round(mse,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个数据集是比较规范的，我们不需要在数据清洗，数据规范上面花费太多时间精力，代码编写起来也比较简单。\n",
    "\n",
    "同样，我们可以使用不同的回归分析模型分析这个数据集，比如使用决策树回归和KNN回归。\n",
    "\n",
    "编写代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树均方误差 = 23.82\n",
      "KNN均方误差 =  27.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# 加载数据\n",
    "data = load_boston()\n",
    "# 分割数据(训练，测试交替：训练-测试；训练-测试)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data.data, data.target, test_size=0.25, random_state=33)\n",
    "\n",
    "# 使用决策树回归模型\n",
    "dec_regressor = DecisionTreeRegressor()\n",
    "dec_regressor.fit(train_x, train_y)\n",
    "pred_y = dec_regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"决策树均方误差 =\",round(mse,2))\n",
    "# 使用KNN回归模型\n",
    "knn_regressor = KNeighborsRegressor()\n",
    "knn_regressor.fit(train_x, train_y)\n",
    "pred_y = knn_regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"KNN均方误差 = \", round(mse, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现相比之下，AdaBoost的均方差（平均方差）更小，也就是结果更优。虽然AdaBoost使用了弱分类器，但是通过50个甚至更多的弱分类器组合起来而形成的强分类器，在很多情况下结果都优于其他算法。因此AdaBoost也是常用的分类和回归算法之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost 与决策树模型的比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在sklearn中的AdaBoost默认采用的是决策树模型，我们可以随机生成一些数据，然后对比下AdaBoost中的弱分类器（也就是决策树弱分类器）、决策树分类器和AdaBoost模型在分类准确率上的表现。\n",
    "\n",
    "如果想要随机生成数据，饿哦们可以使用sklearn中的make_hastie_10_2函数生成二分类数据。假设我们生成12000个数据，取前2000个作为数据集，其余作为训练集。\n",
    "\n",
    "有了数据和训练模型之后，我们就可以编写代码。我们设置了AdaBoost的迭代次数为200，代表AdaBoost由200个分类器组成。针对训练集，我们使用三种模型分别进行训练，然后使用测试集进行预测，并将三个分类器的错误率进行可视化对比，可以看到这三者之间的区别：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# 设置AdaBoost迭代的次数\n",
    "n_estimators = 200\n",
    "# 使用\n",
    "X, y = datasets.make_hastie_10_2(n_samples=12000, random_state=1)\n",
    "# 从12000个数据中取前2000行作为测试集，其余的作为训练集\n",
    "train_x, train_y = X[2000:], y[2000:]\n",
    "test_x, test_y = X[:2000], y[:2000]\n",
    "# 弱分类器\n",
    "dt_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)\n",
    "dt_stump.fit(train_x, train_y)\n",
    "# 对弱分类器进行评分\n",
    "dt_stump_err = 1.0-dt_stump.score(test_x, test_y)\n",
    "# 决策树分类器\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train_x, train_y)\n",
    "dt_err = 1.0-dt.score(test_x, test_y)\n",
    "# AdaBoost分类器\n",
    "ada = AdaBoostClassifier(base_estimator=dt_stump, n_estimators=n_estimators)\n",
    "ada.fit(train_x, train_y)\n",
    "# 三个分类器的错误率可视化\n",
    "fig = plt.figure()\n",
    "# 设置plt正常显示中文\n",
    "# plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 设置图像的参数\n",
    "ax = fig.add_subplot(111)\n",
    "# 设置图例实线和虚线\n",
    "ax.plot([1,n_estimators],[dt_stump_err]*2, 'k-', label=u'决策树弱分类器 错误率')\n",
    "ax.plot([1,n_estimators],[dt_err]*2, 'k--', label=u'决策树模型 错误率')\n",
    "ada_err = np.zeros((n_estimators,))\n",
    "# 遍历每次迭代的结果 i 为迭代次数，pred_y 为预测结果\n",
    "for i, pred_y in enumerate(ada.staged_predict(test_x)):\n",
    "    # 统计错误率\n",
    "    ada_err[i]=zero_one_loss(pred_y, test_y)\n",
    "# 绘制每次迭代的AdaBoost 错误率，绘制错误率的线是橙色的\n",
    "ax.plot(np.arange(n_estimators)+1, ada_err, label='AdaBoost Test 错误率', color='orange')\n",
    "# 设置x和y轴的图例\n",
    "ax.set_xlabel('迭代次数')\n",
    "ax.set_ylabel('错误率')\n",
    "leg=ax.legend(loc='upper right', fancybox=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中我们可以看出来，弱分类器的错误率最高，只比随机分类结果略好，准确率稍微大于50%。决策树模型的错误率明显要低很多。而AdaBoost模型在迭代次数超过25次之后，cuowi错误率有了明显的下降，经过125次迭代之后错误率的变化形式趋于平缓。\n",
    "\n",
    "因此我们能够看出，虽然单独的一个决策树弱分类器效果不好，但是多个决策树弱分类器组合起来形成的AdaBoost分类器，分类效果要好于决策树模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、我们使用AdaBoost回归分析对波士顿的房价进行了预测。因为这是个回归分析的问题，我们直接使用sklearn中的AdaBoostRegressor即可，如果是分类。我们使用AdaBoostClassifier。\n",
    "\n",
    "2、另外我们将AdaBoost分类器、弱分类器和决策分类器做了对比，可以看出经过多个弱分类器组合形成的AdaBoost强分类器，准确率是要明显高于决策树算法。所以AdaBoost的优势在于框架的本身，它通过一种迭代的机制让原本性能不强的分类器组合起来，形成一个强的分类器。\n",
    "\n",
    "3、其实在工作中，我们也能找到类似的案例。IBM服务器最求的是单个服务器性能的强大，比如说打造超级服务器。而Google在创建集群的时候，利用了很多的PC级的服务器，将它们组成集群，整体的性能远比一个超级服务器的性能强大。也就是“三个臭皮匠，顶个诸葛亮”。这也就是AdaBoost的价值所在吧。\n",
    "\n",
    "4、AdaBoost实战\n",
    "- 工具\n",
    "    - 构造\n",
    "        - 分类：AdaBoostClassifier\n",
    "        - 回归：AdaBoostRegressor\n",
    "    - 参数\n",
    "        - base_estimator:弱分类器，可以指定，默认是决策树模型\n",
    "        - n_estimators：算法的最大迭代次数，也就是分类器的个数\n",
    "        - learning_rate:学习率，取值在0-1之间，默认是1.0\n",
    "        - algorithm：采用哪种Boosting算法，默认采用的是SAMME.R\n",
    "        - random_state:代表随机数种子的设置，默认是None\n",
    "        - loss:代表损失函数的设置，默认是linear\n",
    "- 数据集\n",
    "    - 数据集：506条房屋数据，每条数据包含13个指标，以及房屋的价格\n",
    "    - 使用AdaBoost回归分析，并与决策树回归，KNN回归结果进行比较\n",
    "- AdaBoost与决策树的对比\n",
    "    - AdaBoost使用的弱分类器默认是决策树模型\n",
    "    - 准确率：AdaBoost>决策树>弱分类器\n",
    "    - 弱分类器错误率很高，但是将多个弱分类器组合形成的AdaBoost性能要明显好于决策树分类器模型。\n",
    "\n",
    "![](AdaBoost实战.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习：使用AdaBoost算法对泰坦尼克号乘客的生存做预测："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将对泰坦尼克号乘客的生存代码做出修改如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3的cross_val_score准确率为 0.7801\n",
      "AdaBoost的cross_val_score准确率为 0.7858\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# 数据加载\n",
    "train_data = pd.read_csv('./Titanic_data/train.csv')\n",
    "test_data = pd.read_csv('./Titanic_data/test.csv')\n",
    "# print(train_data['Embarked'].value_counts())\n",
    "# 使用平均年龄来填充年龄中的NaN值\n",
    "train_data['Age'].fillna(train_data['Age'].mean(),inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)\n",
    "# 使用票价的均值来填充票价中的NaN值\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\n",
    "# 使用登录最多的港口来填充登录港口的NaN值\n",
    "train_data['Embarked'].fillna('S', inplace=True)\n",
    "test_data['Embarked'].fillna('S',inplace=True)\n",
    "# 特征选择（特征值矩阵）\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['Survived'] # 加上一个生存标签\n",
    "test_features = test_data[features]\n",
    "# 训练集转换类型\n",
    "dvec=DictVectorizer(sparse=False)\n",
    "train_features=dvec.fit_transform(train_features.to_dict(orient='record'))\n",
    "\n",
    "# 弱分类器\n",
    "dt_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)\n",
    "dt_stump.fit(train_features, train_labels)\n",
    "\n",
    "# 构造ID3决策树,去掉criterion='entropy'\n",
    "clf = DecisionTreeClassifier()\n",
    "# 拟合，决策树训练\n",
    "clf.fit(train_features, train_labels)\n",
    "# 测试集类型转换\n",
    "test_features = dvec.transform(test_features.to_dict(orient='record'))\n",
    "# 决策树预测\n",
    "pred_labels = clf.predict(test_features)\n",
    "# 得到决策树的准确率\n",
    "# acc_decision_tree = round(clf.score(train_features, train_labels), 6)\n",
    "# print(u'score 准确率为 %.4lf' % acc_decision_tree)\n",
    "# 使用K折交叉验证 统计决策树的准确率\n",
    "print(u'ID3的cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels,cv=10)))\n",
    "\n",
    "\n",
    "# 设置AdaBoost迭代的次数\n",
    "n_estimators = 200\n",
    "# AdaBoost分类器(指定弱分类器，其实也可以直接使用ada = AdaBoostClassifier())\n",
    "ada = AdaBoostClassifier(base_estimator=dt_stump, n_estimators=n_estimators)\n",
    "ada.fit(train_features, train_labels)\n",
    "# 使用K折交叉验证 统计决策树的准确率\n",
    "print(u'AdaBoost的cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels,cv=10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上面的结果可以知道AdaBoost算法一般会比决策树的准确率高一点，也可以将程序分开写如下代码所示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost的cross_val_score准确率为 0.7779\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# 数据加载\n",
    "train_data = pd.read_csv('./Titanic_data/train.csv')\n",
    "test_data = pd.read_csv('./Titanic_data/test.csv')\n",
    "# print(train_data['Embarked'].value_counts())\n",
    "# 使用平均年龄来填充年龄中的NaN值\n",
    "train_data['Age'].fillna(train_data['Age'].mean(),inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)\n",
    "# 使用票价的均值来填充票价中的NaN值\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\n",
    "# 使用登录最多的港口来填充登录港口的NaN值\n",
    "train_data['Embarked'].fillna('S', inplace=True)\n",
    "test_data['Embarked'].fillna('S',inplace=True)\n",
    "# 特征选择（特征值矩阵）\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['Survived'] # 加上一个生存标签\n",
    "test_features = test_data[features]\n",
    "# 训练集转换类型\n",
    "dvec=DictVectorizer(sparse=False)\n",
    "train_features=dvec.fit_transform(train_features.to_dict(orient='record'))\n",
    "\n",
    "# 弱分类器\n",
    "dt_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)\n",
    "dt_stump.fit(train_features, train_labels)\n",
    "# 设置AdaBoost迭代的次数\n",
    "n_estimators = 200\n",
    "# AdaBoost分类器(指定弱分类器，其实也可以直接使用ada = AdaBoostClassifier())\n",
    "ada = AdaBoostClassifier(base_estimator=dt_stump, n_estimators=n_estimators)\n",
    "ada.fit(train_features, train_labels)\n",
    "# 测试集类型转换\n",
    "test_features = dvec.transform(test_features.to_dict(orient='record'))\n",
    "# 决策树预测\n",
    "pred_labels = clf.predict(test_features)\n",
    "# 使用K折交叉验证 统计决策树的准确率\n",
    "print(u'AdaBoost的cross_val_score准确率为 %.4lf' % np.mean(cross_val_score(clf, train_features, train_labels,cv=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
